[Metadata]
MIT OCW CMS.611J Lecture 7:
    https://www.youtube.com/watch?v=xQANWfUYeNg&list=PLUl4u3cNGP61V4W6yRm1Am5zI94m33dXk&index=12
Sources:

[Postmortem and reflextion presentation]
- Summary of the process of what you are doing
- What you learn
- what you did wrong
- what you are going to do in the future
- In 5 min

[Quality Assurance]
- diferent types of testing
- systematic process
- checks if the product developed is meeting specified requirements 

[Scrum & testing]
Before you finished your task, someone in your team should validate your work
and run your tests as well as their own.


[Types of testing]
1. Technical testing
  - Looking for defects
  - if you are simulating a car, make sure it runs the right velocity and right FPS
2. Playtesting
  - you run your software
3. User testing (not in your team)
  - Someone else tries your software
  - focus testing
    (is it fun, is it a good game)
  - user testing
    (usability? dificulty? expectations?)
4. Security testing
  - Try to hack your code for vulnerabilities

[Usability testing]
 - The only required for this game project
 - We are not talking about testing code, but testing ideas
 
 
[Technical testing basic]
- Technical standards (have them)
- Bug database
- Build and test before check in
- Daily builds, daily play throughs
- Planned feature cuts
  (Plan wich features are going to be cut first)
- Code Freezes (code reviews)
- Asset freezes

[Technical testing advanced]
- Maintain feature lists
- Agree how features should work
- Test newly implemented features as soon as they're done
- Checklist testing, methodological testing of all features, all branches, all possible states.
  (Regression testing, testing features that haven't changed since last checkin to make sure they're still working)
- Remember that checklist testing, and strict feature testing,
  doesn't cover freedom play, getting in the game and just doing stuff to see what happens. Do it too
    
[Bug reporting]
- .What happened. vs .What should had happened.
- .How to reproduce.
- .How common & serious the bug is.
- .Supporting data (links, screenshots, numbers).

[Feedback]
- Critique vs Critiscism
  - Is the game too easy?
  - Do i skip the game track/history
- Take the feedback, discard the testers solutions
  - users try to fit your game to they expectations.
    a shooter user would like to have a gun, even in a strategic game 
[User Testing]
- Engaging game is hard. 
- How the users react to your game.
- Gauging overall game dificulty/challenge
- Test driven design
- Check your UI against actual users

[How User testing]
- Experimental method.
  - Form an hipothesis
  - Create a test for it
  - Gather data
  - Analyze results
- Have a Question or Goal for each focus test
- Develop a Method: standardize your approach
  - Introductory Script
  - List of observations to look for
  - Set of questions to ask your testers
- Review your data and decide what the team should do about it

- Is your user enganging with the game or just pressing random buttons?
- Ask the user what the UI should tell him
- You can show them pictures of the intended UI, so you know early if the user liked or not
- Have a dedicated observer
    - List of things to observe
- What can the user tell you (short) you cannot see
- Ask the player to talk in loud to show his thinking proccess
    - Adults when they don't know what they are doing, don't tell until they figure out
    - Childs usually say they don't understand

[Neutral Questions]
- What are you doing?
- What's your plan?
- What are you doing?
- Timer the amount of time people is struggling at a level

[Data]
- Magnify good stuff
- Minimize bad stuff
The state of your game will affect your data

[Feedback]
- People don't want to tell bad things into your face, 
    they'd rather write on a piece of paper
    
[User testing]
 - Focus test form
    (What's the goal of the test)
 - Observer script / survey
    (How would the user react)
 - User students is not a representative population
 [Bug database]
 - Chira
 - bugzilla
 - buganizer
 
 
 [The goal for today]
 - Finding feedback of your software!
 
 
 
 [RIOT GAMES]
 - Player focus testing (talk to players)
 - All decisions are in term of
    - How much value the adds to the player
    - How much pain causes to the player
 - Custom Anthem for the worldchampionship
    - Do things to represent how players feels
 - Lot of playtesting
 - Lot of user testing
 - Balance, identify overpowerful champions
 - Temporal Scenarios Modes to make the game alive
 - Clarity measure. How clear the information is shown
 - Team test, quickly feedback
 - Guerrilla test, other teams in your company try to explode your work
 - Hardware diference between users
 [User Labs]
 [Insights]
    - Reception / Interest
    - Usage patterns / Errors
    - Players with diferent experience
    - Needs / Desires
    - Beliefs
 [Methods]
    - Observation
    - Think aloud
        (how the UI is showing the info, and how the player is building a model)
        (Strean if consciousness)
    - Interviews / Questionnaire
    - Experimental / Quantitative
        - Give the user a task, account all mistake he made
        - plot the error rate for each user
        - Plot the time each user require to complete certain task
        (you can test joystick, mouse to reach certain regions etc.)
        so you can improve the design
    - Physiological
        - Eye tracking
        - Where are they looking (minimap, abilities, charachter, enemy)
        - Stress/excitement (when they cannot vocalize)
        
 [Case of study: Lucian]
 - Goals: 
    - feel: sleek, speedy, serious
    - Gameplay: Range Damage with finesee gameplay, high skill ceiling
    - Fantasy: Equilibrium, two guns
 - Challanges:
    - How do you let a player feel like a quick 'gun ninja' 
    - does this character fit in the Riot game?
[Research flow]
- Concept testing (determining concept)
    concept: [Noble, elegant | Futuristic but magical | Dark & serious | Each gun has custom effects]
     Survey: [Fantasy | Mood | Personality | Role | Fit in League]
   feedback: [As the guns were in different color, users expected different behaviour,
              it worked in a way i didn't want it to work]
- Lab study (test version a)
- Lab study 2 (test version b based on feedback)
    - Why does it feels slow?
         - Mechanics? Animation?
- Lab study 3 (test version c based on feedback)
- Post lauch (test impact and reception)
- You cannot answer players questions
- you can ask to understand, not to criticise
- ASK AN INITIAL QUESTION, to make comfortable the user. 'how is that?' instead 'how it is feel', your data is really valuable
There's always a researcher in the room


[Focus test, run test]
